start
finish importing
['resnet110']
Now begin to load dataset...
Now begin to load model...
conv1.weight: torch.Size([16, 1, 3, 3])
bn1.weight: torch.Size([16])
bn1.bias: torch.Size([16])
layer1.0.conv1.weight: torch.Size([16, 16, 3, 3])
layer1.0.bn1.weight: torch.Size([16])
layer1.0.bn1.bias: torch.Size([16])
layer1.0.conv2.weight: torch.Size([16, 16, 3, 3])
layer1.0.bn2.weight: torch.Size([16])
layer1.0.bn2.bias: torch.Size([16])
layer1.1.conv1.weight: torch.Size([16, 16, 3, 3])
layer1.1.bn1.weight: torch.Size([16])
layer1.1.bn1.bias: torch.Size([16])
layer1.1.conv2.weight: torch.Size([16, 16, 3, 3])
layer1.1.bn2.weight: torch.Size([16])
layer1.1.bn2.bias: torch.Size([16])
layer1.2.conv1.weight: torch.Size([16, 16, 3, 3])
layer1.2.bn1.weight: torch.Size([16])
layer1.2.bn1.bias: torch.Size([16])
layer1.2.conv2.weight: torch.Size([16, 16, 3, 3])
layer1.2.bn2.weight: torch.Size([16])
layer1.2.bn2.bias: torch.Size([16])
layer1.3.conv1.weight: torch.Size([16, 16, 3, 3])
layer1.3.bn1.weight: torch.Size([16])
layer1.3.bn1.bias: torch.Size([16])
layer1.3.conv2.weight: torch.Size([16, 16, 3, 3])
layer1.3.bn2.weight: torch.Size([16])
layer1.3.bn2.bias: torch.Size([16])
layer1.4.conv1.weight: torch.Size([16, 16, 3, 3])
layer1.4.bn1.weight: torch.Size([16])
layer1.4.bn1.bias: torch.Size([16])
layer1.4.conv2.weight: torch.Size([16, 16, 3, 3])
layer1.4.bn2.weight: torch.Size([16])
layer1.4.bn2.bias: torch.Size([16])
layer1.5.conv1.weight: torch.Size([16, 16, 3, 3])
layer1.5.bn1.weight: torch.Size([16])
layer1.5.bn1.bias: torch.Size([16])
layer1.5.conv2.weight: torch.Size([16, 16, 3, 3])
layer1.5.bn2.weight: torch.Size([16])
layer1.5.bn2.bias: torch.Size([16])
layer1.6.conv1.weight: torch.Size([16, 16, 3, 3])
layer1.6.bn1.weight: torch.Size([16])
layer1.6.bn1.bias: torch.Size([16])
layer1.6.conv2.weight: torch.Size([16, 16, 3, 3])
layer1.6.bn2.weight: torch.Size([16])
layer1.6.bn2.bias: torch.Size([16])
layer1.7.conv1.weight: torch.Size([16, 16, 3, 3])
layer1.7.bn1.weight: torch.Size([16])
layer1.7.bn1.bias: torch.Size([16])
layer1.7.conv2.weight: torch.Size([16, 16, 3, 3])
layer1.7.bn2.weight: torch.Size([16])
layer1.7.bn2.bias: torch.Size([16])
layer1.8.conv1.weight: torch.Size([16, 16, 3, 3])
layer1.8.bn1.weight: torch.Size([16])
layer1.8.bn1.bias: torch.Size([16])
layer1.8.conv2.weight: torch.Size([16, 16, 3, 3])
layer1.8.bn2.weight: torch.Size([16])
layer1.8.bn2.bias: torch.Size([16])
layer1.9.conv1.weight: torch.Size([16, 16, 3, 3])
layer1.9.bn1.weight: torch.Size([16])
layer1.9.bn1.bias: torch.Size([16])
layer1.9.conv2.weight: torch.Size([16, 16, 3, 3])
layer1.9.bn2.weight: torch.Size([16])
layer1.9.bn2.bias: torch.Size([16])
layer1.10.conv1.weight: torch.Size([16, 16, 3, 3])
layer1.10.bn1.weight: torch.Size([16])
layer1.10.bn1.bias: torch.Size([16])
layer1.10.conv2.weight: torch.Size([16, 16, 3, 3])
layer1.10.bn2.weight: torch.Size([16])
layer1.10.bn2.bias: torch.Size([16])
layer1.11.conv1.weight: torch.Size([16, 16, 3, 3])
layer1.11.bn1.weight: torch.Size([16])
layer1.11.bn1.bias: torch.Size([16])
layer1.11.conv2.weight: torch.Size([16, 16, 3, 3])
layer1.11.bn2.weight: torch.Size([16])
layer1.11.bn2.bias: torch.Size([16])
layer1.12.conv1.weight: torch.Size([16, 16, 3, 3])
layer1.12.bn1.weight: torch.Size([16])
layer1.12.bn1.bias: torch.Size([16])
layer1.12.conv2.weight: torch.Size([16, 16, 3, 3])
layer1.12.bn2.weight: torch.Size([16])
layer1.12.bn2.bias: torch.Size([16])
layer1.13.conv1.weight: torch.Size([16, 16, 3, 3])
layer1.13.bn1.weight: torch.Size([16])
layer1.13.bn1.bias: torch.Size([16])
layer1.13.conv2.weight: torch.Size([16, 16, 3, 3])
layer1.13.bn2.weight: torch.Size([16])
layer1.13.bn2.bias: torch.Size([16])
layer1.14.conv1.weight: torch.Size([16, 16, 3, 3])
layer1.14.bn1.weight: torch.Size([16])
layer1.14.bn1.bias: torch.Size([16])
layer1.14.conv2.weight: torch.Size([16, 16, 3, 3])
layer1.14.bn2.weight: torch.Size([16])
layer1.14.bn2.bias: torch.Size([16])
layer1.15.conv1.weight: torch.Size([16, 16, 3, 3])
layer1.15.bn1.weight: torch.Size([16])
layer1.15.bn1.bias: torch.Size([16])
layer1.15.conv2.weight: torch.Size([16, 16, 3, 3])
layer1.15.bn2.weight: torch.Size([16])
layer1.15.bn2.bias: torch.Size([16])
layer1.16.conv1.weight: torch.Size([16, 16, 3, 3])
layer1.16.bn1.weight: torch.Size([16])
layer1.16.bn1.bias: torch.Size([16])
layer1.16.conv2.weight: torch.Size([16, 16, 3, 3])
layer1.16.bn2.weight: torch.Size([16])
layer1.16.bn2.bias: torch.Size([16])
layer1.17.conv1.weight: torch.Size([16, 16, 3, 3])
layer1.17.bn1.weight: torch.Size([16])
layer1.17.bn1.bias: torch.Size([16])
layer1.17.conv2.weight: torch.Size([16, 16, 3, 3])
layer1.17.bn2.weight: torch.Size([16])
layer1.17.bn2.bias: torch.Size([16])
layer2.0.conv1.weight: torch.Size([32, 16, 3, 3])
layer2.0.bn1.weight: torch.Size([32])
layer2.0.bn1.bias: torch.Size([32])
layer2.0.conv2.weight: torch.Size([32, 32, 3, 3])
layer2.0.bn2.weight: torch.Size([32])
layer2.0.bn2.bias: torch.Size([32])
layer2.0.shortcut.0.weight: torch.Size([32, 16, 1, 1])
layer2.0.shortcut.1.weight: torch.Size([32])
layer2.0.shortcut.1.bias: torch.Size([32])
layer2.1.conv1.weight: torch.Size([32, 32, 3, 3])
layer2.1.bn1.weight: torch.Size([32])
layer2.1.bn1.bias: torch.Size([32])
layer2.1.conv2.weight: torch.Size([32, 32, 3, 3])
layer2.1.bn2.weight: torch.Size([32])
layer2.1.bn2.bias: torch.Size([32])
layer2.2.conv1.weight: torch.Size([32, 32, 3, 3])
layer2.2.bn1.weight: torch.Size([32])
layer2.2.bn1.bias: torch.Size([32])
layer2.2.conv2.weight: torch.Size([32, 32, 3, 3])
layer2.2.bn2.weight: torch.Size([32])
layer2.2.bn2.bias: torch.Size([32])
layer2.3.conv1.weight: torch.Size([32, 32, 3, 3])
layer2.3.bn1.weight: torch.Size([32])
layer2.3.bn1.bias: torch.Size([32])
layer2.3.conv2.weight: torch.Size([32, 32, 3, 3])
layer2.3.bn2.weight: torch.Size([32])
layer2.3.bn2.bias: torch.Size([32])
layer2.4.conv1.weight: torch.Size([32, 32, 3, 3])
layer2.4.bn1.weight: torch.Size([32])
layer2.4.bn1.bias: torch.Size([32])
layer2.4.conv2.weight: torch.Size([32, 32, 3, 3])
layer2.4.bn2.weight: torch.Size([32])
layer2.4.bn2.bias: torch.Size([32])
layer2.5.conv1.weight: torch.Size([32, 32, 3, 3])
layer2.5.bn1.weight: torch.Size([32])
layer2.5.bn1.bias: torch.Size([32])
layer2.5.conv2.weight: torch.Size([32, 32, 3, 3])
layer2.5.bn2.weight: torch.Size([32])
layer2.5.bn2.bias: torch.Size([32])
layer2.6.conv1.weight: torch.Size([32, 32, 3, 3])
layer2.6.bn1.weight: torch.Size([32])
layer2.6.bn1.bias: torch.Size([32])
layer2.6.conv2.weight: torch.Size([32, 32, 3, 3])
layer2.6.bn2.weight: torch.Size([32])
layer2.6.bn2.bias: torch.Size([32])
layer2.7.conv1.weight: torch.Size([32, 32, 3, 3])
layer2.7.bn1.weight: torch.Size([32])
layer2.7.bn1.bias: torch.Size([32])
layer2.7.conv2.weight: torch.Size([32, 32, 3, 3])
layer2.7.bn2.weight: torch.Size([32])
layer2.7.bn2.bias: torch.Size([32])
layer2.8.conv1.weight: torch.Size([32, 32, 3, 3])
layer2.8.bn1.weight: torch.Size([32])
layer2.8.bn1.bias: torch.Size([32])
layer2.8.conv2.weight: torch.Size([32, 32, 3, 3])
layer2.8.bn2.weight: torch.Size([32])
layer2.8.bn2.bias: torch.Size([32])
layer2.9.conv1.weight: torch.Size([32, 32, 3, 3])
layer2.9.bn1.weight: torch.Size([32])
layer2.9.bn1.bias: torch.Size([32])
layer2.9.conv2.weight: torch.Size([32, 32, 3, 3])
layer2.9.bn2.weight: torch.Size([32])
layer2.9.bn2.bias: torch.Size([32])
layer2.10.conv1.weight: torch.Size([32, 32, 3, 3])
layer2.10.bn1.weight: torch.Size([32])
layer2.10.bn1.bias: torch.Size([32])
layer2.10.conv2.weight: torch.Size([32, 32, 3, 3])
layer2.10.bn2.weight: torch.Size([32])
layer2.10.bn2.bias: torch.Size([32])
layer2.11.conv1.weight: torch.Size([32, 32, 3, 3])
layer2.11.bn1.weight: torch.Size([32])
layer2.11.bn1.bias: torch.Size([32])
layer2.11.conv2.weight: torch.Size([32, 32, 3, 3])
layer2.11.bn2.weight: torch.Size([32])
layer2.11.bn2.bias: torch.Size([32])
layer2.12.conv1.weight: torch.Size([32, 32, 3, 3])
layer2.12.bn1.weight: torch.Size([32])
layer2.12.bn1.bias: torch.Size([32])
layer2.12.conv2.weight: torch.Size([32, 32, 3, 3])
layer2.12.bn2.weight: torch.Size([32])
layer2.12.bn2.bias: torch.Size([32])
layer2.13.conv1.weight: torch.Size([32, 32, 3, 3])
layer2.13.bn1.weight: torch.Size([32])
layer2.13.bn1.bias: torch.Size([32])
layer2.13.conv2.weight: torch.Size([32, 32, 3, 3])
layer2.13.bn2.weight: torch.Size([32])
layer2.13.bn2.bias: torch.Size([32])
layer2.14.conv1.weight: torch.Size([32, 32, 3, 3])
layer2.14.bn1.weight: torch.Size([32])
layer2.14.bn1.bias: torch.Size([32])
layer2.14.conv2.weight: torch.Size([32, 32, 3, 3])
layer2.14.bn2.weight: torch.Size([32])
layer2.14.bn2.bias: torch.Size([32])
layer2.15.conv1.weight: torch.Size([32, 32, 3, 3])
layer2.15.bn1.weight: torch.Size([32])
layer2.15.bn1.bias: torch.Size([32])
layer2.15.conv2.weight: torch.Size([32, 32, 3, 3])
layer2.15.bn2.weight: torch.Size([32])
layer2.15.bn2.bias: torch.Size([32])
layer2.16.conv1.weight: torch.Size([32, 32, 3, 3])
layer2.16.bn1.weight: torch.Size([32])
layer2.16.bn1.bias: torch.Size([32])
layer2.16.conv2.weight: torch.Size([32, 32, 3, 3])
layer2.16.bn2.weight: torch.Size([32])
layer2.16.bn2.bias: torch.Size([32])
layer2.17.conv1.weight: torch.Size([32, 32, 3, 3])
layer2.17.bn1.weight: torch.Size([32])
layer2.17.bn1.bias: torch.Size([32])
layer2.17.conv2.weight: torch.Size([32, 32, 3, 3])
layer2.17.bn2.weight: torch.Size([32])
layer2.17.bn2.bias: torch.Size([32])
layer3.0.conv1.weight: torch.Size([64, 32, 3, 3])
layer3.0.bn1.weight: torch.Size([64])
layer3.0.bn1.bias: torch.Size([64])
layer3.0.conv2.weight: torch.Size([64, 64, 3, 3])
layer3.0.bn2.weight: torch.Size([64])
layer3.0.bn2.bias: torch.Size([64])
layer3.0.shortcut.0.weight: torch.Size([64, 32, 1, 1])
layer3.0.shortcut.1.weight: torch.Size([64])
layer3.0.shortcut.1.bias: torch.Size([64])
layer3.1.conv1.weight: torch.Size([64, 64, 3, 3])
layer3.1.bn1.weight: torch.Size([64])
layer3.1.bn1.bias: torch.Size([64])
layer3.1.conv2.weight: torch.Size([64, 64, 3, 3])
layer3.1.bn2.weight: torch.Size([64])
layer3.1.bn2.bias: torch.Size([64])
layer3.2.conv1.weight: torch.Size([64, 64, 3, 3])
layer3.2.bn1.weight: torch.Size([64])
layer3.2.bn1.bias: torch.Size([64])
layer3.2.conv2.weight: torch.Size([64, 64, 3, 3])
layer3.2.bn2.weight: torch.Size([64])
layer3.2.bn2.bias: torch.Size([64])
layer3.3.conv1.weight: torch.Size([64, 64, 3, 3])
layer3.3.bn1.weight: torch.Size([64])
layer3.3.bn1.bias: torch.Size([64])
layer3.3.conv2.weight: torch.Size([64, 64, 3, 3])
layer3.3.bn2.weight: torch.Size([64])
layer3.3.bn2.bias: torch.Size([64])
layer3.4.conv1.weight: torch.Size([64, 64, 3, 3])
layer3.4.bn1.weight: torch.Size([64])
layer3.4.bn1.bias: torch.Size([64])
layer3.4.conv2.weight: torch.Size([64, 64, 3, 3])
layer3.4.bn2.weight: torch.Size([64])
layer3.4.bn2.bias: torch.Size([64])
layer3.5.conv1.weight: torch.Size([64, 64, 3, 3])
layer3.5.bn1.weight: torch.Size([64])
layer3.5.bn1.bias: torch.Size([64])
layer3.5.conv2.weight: torch.Size([64, 64, 3, 3])
layer3.5.bn2.weight: torch.Size([64])
layer3.5.bn2.bias: torch.Size([64])
layer3.6.conv1.weight: torch.Size([64, 64, 3, 3])
layer3.6.bn1.weight: torch.Size([64])
layer3.6.bn1.bias: torch.Size([64])
layer3.6.conv2.weight: torch.Size([64, 64, 3, 3])
layer3.6.bn2.weight: torch.Size([64])
layer3.6.bn2.bias: torch.Size([64])
layer3.7.conv1.weight: torch.Size([64, 64, 3, 3])
layer3.7.bn1.weight: torch.Size([64])
layer3.7.bn1.bias: torch.Size([64])
layer3.7.conv2.weight: torch.Size([64, 64, 3, 3])
layer3.7.bn2.weight: torch.Size([64])
layer3.7.bn2.bias: torch.Size([64])
layer3.8.conv1.weight: torch.Size([64, 64, 3, 3])
layer3.8.bn1.weight: torch.Size([64])
layer3.8.bn1.bias: torch.Size([64])
layer3.8.conv2.weight: torch.Size([64, 64, 3, 3])
layer3.8.bn2.weight: torch.Size([64])
layer3.8.bn2.bias: torch.Size([64])
layer3.9.conv1.weight: torch.Size([64, 64, 3, 3])
layer3.9.bn1.weight: torch.Size([64])
layer3.9.bn1.bias: torch.Size([64])
layer3.9.conv2.weight: torch.Size([64, 64, 3, 3])
layer3.9.bn2.weight: torch.Size([64])
layer3.9.bn2.bias: torch.Size([64])
layer3.10.conv1.weight: torch.Size([64, 64, 3, 3])
layer3.10.bn1.weight: torch.Size([64])
layer3.10.bn1.bias: torch.Size([64])
layer3.10.conv2.weight: torch.Size([64, 64, 3, 3])
layer3.10.bn2.weight: torch.Size([64])
layer3.10.bn2.bias: torch.Size([64])
layer3.11.conv1.weight: torch.Size([64, 64, 3, 3])
layer3.11.bn1.weight: torch.Size([64])
layer3.11.bn1.bias: torch.Size([64])
layer3.11.conv2.weight: torch.Size([64, 64, 3, 3])
layer3.11.bn2.weight: torch.Size([64])
layer3.11.bn2.bias: torch.Size([64])
layer3.12.conv1.weight: torch.Size([64, 64, 3, 3])
layer3.12.bn1.weight: torch.Size([64])
layer3.12.bn1.bias: torch.Size([64])
layer3.12.conv2.weight: torch.Size([64, 64, 3, 3])
layer3.12.bn2.weight: torch.Size([64])
layer3.12.bn2.bias: torch.Size([64])
layer3.13.conv1.weight: torch.Size([64, 64, 3, 3])
layer3.13.bn1.weight: torch.Size([64])
layer3.13.bn1.bias: torch.Size([64])
layer3.13.conv2.weight: torch.Size([64, 64, 3, 3])
layer3.13.bn2.weight: torch.Size([64])
layer3.13.bn2.bias: torch.Size([64])
layer3.14.conv1.weight: torch.Size([64, 64, 3, 3])
layer3.14.bn1.weight: torch.Size([64])
layer3.14.bn1.bias: torch.Size([64])
layer3.14.conv2.weight: torch.Size([64, 64, 3, 3])
layer3.14.bn2.weight: torch.Size([64])
layer3.14.bn2.bias: torch.Size([64])
layer3.15.conv1.weight: torch.Size([64, 64, 3, 3])
layer3.15.bn1.weight: torch.Size([64])
layer3.15.bn1.bias: torch.Size([64])
layer3.15.conv2.weight: torch.Size([64, 64, 3, 3])
layer3.15.bn2.weight: torch.Size([64])
layer3.15.bn2.bias: torch.Size([64])
layer3.16.conv1.weight: torch.Size([64, 64, 3, 3])
layer3.16.bn1.weight: torch.Size([64])
layer3.16.bn1.bias: torch.Size([64])
layer3.16.conv2.weight: torch.Size([64, 64, 3, 3])
layer3.16.bn2.weight: torch.Size([64])
layer3.16.bn2.bias: torch.Size([64])
layer3.17.conv1.weight: torch.Size([64, 64, 3, 3])
layer3.17.bn1.weight: torch.Size([64])
layer3.17.bn1.bias: torch.Size([64])
layer3.17.conv2.weight: torch.Size([64, 64, 3, 3])
layer3.17.bn2.weight: torch.Size([64])
layer3.17.bn2.bias: torch.Size([64])
linear.weight: torch.Size([4, 64])
linear.bias: torch.Size([4])
Now begin to train model...
Train: Epoch: [0][0/298]	Time 10.180 (10.180)	Data 0.971 (0.971)	Loss 0.1975 (0.1975)	Prec@1 90.625 (90.625)
Train: Epoch: [0][20/298]	Time 1.681 (2.099)	Data 0.923 (0.937)	Loss 0.2334 (0.2896)	Prec@1 93.750 (88.095)
Train: Epoch: [0][40/298]	Time 1.647 (1.930)	Data 0.889 (0.965)	Loss 0.2760 (0.2832)	Prec@1 87.500 (88.338)
Train: Epoch: [0][60/298]	Time 1.841 (1.881)	Data 1.082 (0.984)	Loss 0.1634 (0.2878)	Prec@1 93.750 (88.781)
Train: Epoch: [0][80/298]	Time 2.093 (1.860)	Data 1.335 (0.997)	Loss 0.2578 (0.2943)	Prec@1 87.500 (88.657)
Train: Epoch: [0][100/298]	Time 1.513 (1.840)	Data 0.754 (0.998)	Loss 0.1802 (0.2991)	Prec@1 93.750 (88.026)
Train: Epoch: [0][120/298]	Time 1.808 (1.822)	Data 1.049 (0.993)	Loss 0.3019 (0.3035)	Prec@1 87.500 (87.707)
Train: Epoch: [0][140/298]	Time 2.075 (1.812)	Data 1.316 (0.994)	Loss 0.1332 (0.3014)	Prec@1 96.875 (88.187)
Train: Epoch: [0][160/298]	Time 1.638 (1.809)	Data 0.879 (0.998)	Loss 0.2836 (0.3088)	Prec@1 90.625 (87.830)
Train: Epoch: [0][180/298]	Time 1.613 (1.801)	Data 0.855 (0.996)	Loss 0.3628 (0.3091)	Prec@1 90.625 (87.707)
Train: Epoch: [0][200/298]	Time 1.664 (1.785)	Data 0.905 (0.984)	Loss 0.3700 (0.3092)	Prec@1 87.500 (87.733)
Train: Epoch: [0][220/298]	Time 1.767 (1.775)	Data 1.009 (0.978)	Loss 0.5152 (0.3166)	Prec@1 78.125 (87.585)
Train: Epoch: [0][240/298]	Time 1.567 (1.772)	Data 0.809 (0.978)	Loss 0.2729 (0.3160)	Prec@1 90.625 (87.565)
Train: Epoch: [0][260/298]	Time 1.928 (1.766)	Data 1.169 (0.975)	Loss 0.4827 (0.3158)	Prec@1 84.375 (87.668)
Train: Epoch: [0][280/298]	Time 1.626 (1.760)	Data 0.867 (0.971)	Loss 0.3492 (0.3176)	Prec@1 78.125 (87.589)
current lr 1.00000e-03
Valid: Test: [0/75]	Time 1.438 (1.438)	Loss 0.7672 (0.7672)	Prec@1 75.000 (75.000)
Valid: Test: [20/75]	Time 0.916 (1.137)	Loss 0.5079 (0.5623)	Prec@1 84.375 (79.315)
Valid: Test: [40/75]	Time 0.917 (1.110)	Loss 0.6775 (0.5802)	Prec@1 71.875 (77.363)
Valid: Test: [60/75]	Time 1.173 (1.122)	Loss 0.4958 (0.5902)	Prec@1 81.250 (77.408)
 * Prec@1 77.166
Checkpoint saved to ./resnet_model/model.th
Best model saved to ./resnet_model/model_best.th
torch.Size([32, 1, 194, 259])
torch.Size([32, 1, 194, 259])
torch.Size([32, 1, 194, 259])
torch.Size([32, 1, 194, 259])
torch.Size([32, 1, 194, 259])
torch.Size([32, 1, 194, 259])
torch.Size([32, 1, 194, 259])
torch.Size([32, 1, 194, 259])
torch.Size([32, 1, 194, 259])
torch.Size([32, 1, 194, 259])
torch.Size([32, 1, 194, 259])
torch.Size([32, 1, 194, 259])
torch.Size([32, 1, 194, 259])
torch.Size([32, 1, 194, 259])
torch.Size([32, 1, 194, 259])
torch.Size([32, 1, 194, 259])
torch.Size([32, 1, 194, 259])
torch.Size([32, 1, 194, 259])
torch.Size([32, 1, 194, 259])
torch.Size([32, 1, 194, 259])
torch.Size([32, 1, 194, 259])
torch.Size([32, 1, 194, 259])
torch.Size([32, 1, 194, 259])
torch.Size([32, 1, 194, 259])
torch.Size([32, 1, 194, 259])
torch.Size([32, 1, 194, 259])
torch.Size([32, 1, 194, 259])
torch.Size([32, 1, 194, 259])
torch.Size([32, 1, 194, 259])
torch.Size([32, 1, 194, 259])
torch.Size([32, 1, 194, 259])
torch.Size([32, 1, 194, 259])
torch.Size([32, 1, 194, 259])
torch.Size([32, 1, 194, 259])
torch.Size([32, 1, 194, 259])
torch.Size([32, 1, 194, 259])
torch.Size([32, 1, 194, 259])
torch.Size([32, 1, 194, 259])
torch.Size([32, 1, 194, 259])
torch.Size([32, 1, 194, 259])
torch.Size([32, 1, 194, 259])
torch.Size([32, 1, 194, 259])
torch.Size([32, 1, 194, 259])
torch.Size([32, 1, 194, 259])
torch.Size([32, 1, 194, 259])
torch.Size([32, 1, 194, 259])
torch.Size([32, 1, 194, 259])
torch.Size([32, 1, 194, 259])
torch.Size([32, 1, 194, 259])
torch.Size([32, 1, 194, 259])
torch.Size([32, 1, 194, 259])
torch.Size([32, 1, 194, 259])
torch.Size([32, 1, 194, 259])
torch.Size([32, 1, 194, 259])
torch.Size([32, 1, 194, 259])
torch.Size([32, 1, 194, 259])
torch.Size([32, 1, 194, 259])
torch.Size([32, 1, 194, 259])
torch.Size([32, 1, 194, 259])
torch.Size([32, 1, 194, 259])
torch.Size([32, 1, 194, 259])
torch.Size([32, 1, 194, 259])
torch.Size([32, 1, 194, 259])
torch.Size([32, 1, 194, 259])
torch.Size([32, 1, 194, 259])
torch.Size([32, 1, 194, 259])
torch.Size([32, 1, 194, 259])
torch.Size([32, 1, 194, 259])
torch.Size([32, 1, 194, 259])
torch.Size([32, 1, 194, 259])
torch.Size([32, 1, 194, 259])
torch.Size([32, 1, 194, 259])
torch.Size([32, 1, 194, 259])
torch.Size([32, 1, 194, 259])
torch.Size([32, 1, 194, 259])
torch.Size([32, 1, 194, 259])
torch.Size([15, 1, 194, 259])
Train: Epoch: [1][0/298]	Time 1.960 (1.960)	Data 1.201 (1.201)	Loss 0.3131 (0.3131)	Prec@1 84.375 (84.375)
Train: Epoch: [1][20/298]	Time 1.470 (1.721)	Data 0.711 (0.963)	Loss 0.3375 (0.3098)	Prec@1 90.625 (87.202)
Train: Epoch: [1][40/298]	Time 1.499 (1.705)	Data 0.740 (0.946)	Loss 0.3711 (0.3145)	Prec@1 81.250 (86.814)
Train: Epoch: [1][60/298]	Time 1.600 (1.708)	Data 0.841 (0.950)	Loss 0.2120 (0.3047)	Prec@1 87.500 (87.449)
Train: Epoch: [1][80/298]	Time 1.849 (1.744)	Data 1.090 (0.985)	Loss 0.3443 (0.3138)	Prec@1 90.625 (86.998)
Train: Epoch: [1][100/298]	Time 1.640 (1.738)	Data 0.881 (0.979)	Loss 0.1252 (0.3201)	Prec@1 100.000 (86.850)
Train: Epoch: [1][120/298]	Time 1.485 (1.728)	Data 0.726 (0.969)	Loss 0.4494 (0.3221)	Prec@1 90.625 (86.906)
Train: Epoch: [1][140/298]	Time 1.574 (1.727)	Data 0.816 (0.968)	Loss 0.3253 (0.3192)	Prec@1 87.500 (87.145)
Train: Epoch: [1][160/298]	Time 1.946 (1.727)	Data 1.188 (0.968)	Loss 0.2660 (0.3157)	Prec@1 93.750 (87.325)
Train: Epoch: [1][180/298]	Time 1.655 (1.728)	Data 0.896 (0.969)	Loss 0.3582 (0.3147)	Prec@1 81.250 (87.379)
Train: Epoch: [1][200/298]	Time 1.590 (1.719)	Data 0.832 (0.960)	Loss 0.2813 (0.3124)	Prec@1 90.625 (87.345)
Train: Epoch: [1][220/298]	Time 1.378 (1.714)	Data 0.619 (0.955)	Loss 0.2256 (0.3200)	Prec@1 96.875 (87.019)
Train: Epoch: [1][240/298]	Time 1.985 (1.712)	Data 1.227 (0.953)	Loss 0.2641 (0.3213)	Prec@1 90.625 (86.942)
Train: Epoch: [1][260/298]	Time 1.872 (1.714)	Data 1.114 (0.956)	Loss 0.4161 (0.3276)	Prec@1 84.375 (86.818)
Train: Epoch: [1][280/298]	Time 1.584 (1.713)	Data 0.825 (0.954)	Loss 0.1862 (0.3277)	Prec@1 93.750 (86.844)
current lr 1.00000e-03
Valid: Test: [0/75]	Time 1.687 (1.687)	Loss 1.8731 (1.8731)	Prec@1 53.125 (53.125)
Valid: Test: [20/75]	Time 1.033 (1.200)	Loss 1.6972 (1.5922)	Prec@1 53.125 (56.994)
Valid: Test: [40/75]	Time 1.039 (1.126)	Loss 2.5429 (1.6304)	Prec@1 37.500 (56.784)
Valid: Test: [60/75]	Time 0.964 (1.067)	Loss 1.8102 (1.6094)	Prec@1 53.125 (57.377)
 * Prec@1 57.696
Checkpoint saved to ./resnet_model/model.th
Train: Epoch: [2][0/298]	Time 1.350 (1.350)	Data 0.592 (0.592)	Loss 0.3288 (0.3288)	Prec@1 93.750 (93.750)
Train: Epoch: [2][20/298]	Time 1.123 (1.366)	Data 0.364 (0.608)	Loss 0.5697 (0.4659)	Prec@1 75.000 (81.250)
Train: Epoch: [2][40/298]	Time 1.424 (1.395)	Data 0.666 (0.637)	Loss 0.3055 (0.4412)	Prec@1 90.625 (82.546)
Train: Epoch: [2][60/298]	Time 1.381 (1.404)	Data 0.623 (0.645)	Loss 0.1803 (0.3904)	Prec@1 93.750 (84.682)
Train: Epoch: [2][80/298]	Time 1.452 (1.427)	Data 0.694 (0.668)	Loss 0.3939 (0.3792)	Prec@1 87.500 (84.915)
Train: Epoch: [2][100/298]	Time 1.551 (1.439)	Data 0.793 (0.681)	Loss 0.3740 (0.3609)	Prec@1 78.125 (85.613)
Train: Epoch: [2][120/298]	Time 1.520 (1.458)	Data 0.762 (0.700)	Loss 0.2059 (0.3533)	Prec@1 90.625 (85.950)
Train: Epoch: [2][140/298]	Time 1.529 (1.471)	Data 0.771 (0.713)	Loss 0.3607 (0.3486)	Prec@1 78.125 (86.215)
Train: Epoch: [2][160/298]	Time 1.617 (1.480)	Data 0.859 (0.722)	Loss 0.2261 (0.3435)	Prec@1 93.750 (86.530)
Train: Epoch: [2][180/298]	Time 1.681 (1.486)	Data 0.922 (0.727)	Loss 0.4614 (0.3379)	Prec@1 90.625 (86.775)
Train: Epoch: [2][200/298]	Time 1.788 (1.496)	Data 1.029 (0.738)	Loss 0.2522 (0.3323)	Prec@1 90.625 (86.987)
Train: Epoch: [2][220/298]	Time 1.997 (1.500)	Data 1.238 (0.742)	Loss 0.2840 (0.3255)	Prec@1 90.625 (87.274)
Train: Epoch: [2][240/298]	Time 1.448 (1.510)	Data 0.690 (0.751)	Loss 0.4520 (0.3233)	Prec@1 75.000 (87.318)
Train: Epoch: [2][260/298]	Time 1.162 (1.511)	Data 0.402 (0.753)	Loss 0.6287 (0.3231)	Prec@1 75.000 (87.296)
Train: Epoch: [2][280/298]	Time 1.652 (1.515)	Data 0.893 (0.757)	Loss 0.1415 (0.3216)	Prec@1 93.750 (87.344)
current lr 1.00000e-03
Valid: Test: [0/75]	Time 0.950 (0.950)	Loss 0.7479 (0.7479)	Prec@1 81.250 (81.250)
Valid: Test: [20/75]	Time 1.015 (1.022)	Loss 0.4451 (0.4415)	Prec@1 87.500 (82.887)
Valid: Test: [40/75]	Time 1.285 (1.005)	Loss 0.6381 (0.4671)	Prec@1 75.000 (81.631)
Valid: Test: [60/75]	Time 0.714 (0.983)	Loss 0.2491 (0.4666)	Prec@1 93.750 (81.967)
 * Prec@1 81.539
Checkpoint saved to ./resnet_model/model.th
Best model saved to ./resnet_model/model_best.th
torch.Size([32, 1, 194, 259])
torch.Size([32, 1, 194, 259])
torch.Size([32, 1, 194, 259])
torch.Size([32, 1, 194, 259])
torch.Size([32, 1, 194, 259])
torch.Size([32, 1, 194, 259])
torch.Size([32, 1, 194, 259])
torch.Size([32, 1, 194, 259])
torch.Size([32, 1, 194, 259])
torch.Size([32, 1, 194, 259])
torch.Size([32, 1, 194, 259])
torch.Size([32, 1, 194, 259])
torch.Size([32, 1, 194, 259])
torch.Size([32, 1, 194, 259])
torch.Size([32, 1, 194, 259])
torch.Size([32, 1, 194, 259])
torch.Size([32, 1, 194, 259])
torch.Size([32, 1, 194, 259])
torch.Size([32, 1, 194, 259])
torch.Size([32, 1, 194, 259])
torch.Size([32, 1, 194, 259])
torch.Size([32, 1, 194, 259])
torch.Size([32, 1, 194, 259])
torch.Size([32, 1, 194, 259])
torch.Size([32, 1, 194, 259])
torch.Size([32, 1, 194, 259])
torch.Size([32, 1, 194, 259])
torch.Size([32, 1, 194, 259])
torch.Size([32, 1, 194, 259])
torch.Size([32, 1, 194, 259])
torch.Size([32, 1, 194, 259])
torch.Size([32, 1, 194, 259])
torch.Size([32, 1, 194, 259])
torch.Size([32, 1, 194, 259])
torch.Size([32, 1, 194, 259])
torch.Size([32, 1, 194, 259])
torch.Size([32, 1, 194, 259])
torch.Size([32, 1, 194, 259])
torch.Size([32, 1, 194, 259])
torch.Size([32, 1, 194, 259])
torch.Size([32, 1, 194, 259])
torch.Size([32, 1, 194, 259])
torch.Size([32, 1, 194, 259])
torch.Size([32, 1, 194, 259])
torch.Size([32, 1, 194, 259])
torch.Size([32, 1, 194, 259])
torch.Size([32, 1, 194, 259])
torch.Size([32, 1, 194, 259])
torch.Size([32, 1, 194, 259])
torch.Size([32, 1, 194, 259])
torch.Size([32, 1, 194, 259])
torch.Size([32, 1, 194, 259])
torch.Size([32, 1, 194, 259])
torch.Size([32, 1, 194, 259])
torch.Size([32, 1, 194, 259])
torch.Size([32, 1, 194, 259])
torch.Size([32, 1, 194, 259])
torch.Size([32, 1, 194, 259])
torch.Size([32, 1, 194, 259])
torch.Size([32, 1, 194, 259])
torch.Size([32, 1, 194, 259])
torch.Size([32, 1, 194, 259])
torch.Size([32, 1, 194, 259])
torch.Size([32, 1, 194, 259])
torch.Size([32, 1, 194, 259])
torch.Size([32, 1, 194, 259])
torch.Size([32, 1, 194, 259])
torch.Size([32, 1, 194, 259])
torch.Size([32, 1, 194, 259])
torch.Size([32, 1, 194, 259])
torch.Size([32, 1, 194, 259])
torch.Size([32, 1, 194, 259])
torch.Size([32, 1, 194, 259])
torch.Size([32, 1, 194, 259])
torch.Size([32, 1, 194, 259])
torch.Size([32, 1, 194, 259])
torch.Size([15, 1, 194, 259])
Train: Epoch: [3][0/298]	Time 1.346 (1.346)	Data 0.587 (0.587)	Loss 0.2183 (0.2183)	Prec@1 93.750 (93.750)
Train: Epoch: [3][20/298]	Time 1.251 (1.469)	Data 0.492 (0.710)	Loss 0.1720 (0.2600)	Prec@1 93.750 (90.030)
Train: Epoch: [3][40/298]	Time 1.383 (1.522)	Data 0.625 (0.763)	Loss 0.3753 (0.2746)	Prec@1 90.625 (89.405)
Train: Epoch: [3][60/298]	Time 1.516 (1.519)	Data 0.758 (0.760)	Loss 0.4124 (0.2742)	Prec@1 84.375 (89.395)
Train: Epoch: [3][80/298]	Time 1.408 (1.485)	Data 0.649 (0.726)	Loss 0.2384 (0.2705)	Prec@1 87.500 (89.699)
Train: Epoch: [3][100/298]	Time 1.548 (1.496)	Data 0.790 (0.737)	Loss 0.4113 (0.2702)	Prec@1 90.625 (89.480)
Train: Epoch: [3][120/298]	Time 1.480 (1.497)	Data 0.721 (0.739)	Loss 0.3643 (0.2672)	Prec@1 84.375 (89.721)
Train: Epoch: [3][140/298]	Time 1.546 (1.505)	Data 0.788 (0.747)	Loss 0.2959 (0.2710)	Prec@1 81.250 (89.273)
Train: Epoch: [3][160/298]	Time 1.306 (1.558)	Data 0.548 (0.799)	Loss 0.2531 (0.2724)	Prec@1 87.500 (89.014)
Train: Epoch: [3][180/298]	Time 1.511 (1.555)	Data 0.753 (0.797)	Loss 0.4118 (0.2724)	Prec@1 90.625 (89.037)
Train: Epoch: [3][200/298]	Time 1.542 (1.559)	Data 0.784 (0.800)	Loss 0.3692 (0.2731)	Prec@1 87.500 (89.008)
Train: Epoch: [3][220/298]	Time 1.782 (1.566)	Data 1.023 (0.807)	Loss 0.4708 (0.2773)	Prec@1 84.375 (88.843)
Train: Epoch: [3][240/298]	Time 1.832 (1.569)	Data 1.074 (0.810)	Loss 0.2711 (0.2778)	Prec@1 90.625 (88.810)
Train: Epoch: [3][260/298]	Time 1.705 (1.572)	Data 0.946 (0.813)	Loss 0.3354 (0.2793)	Prec@1 87.500 (88.793)
Train: Epoch: [3][280/298]	Time 1.734 (1.577)	Data 0.976 (0.818)	Loss 0.7066 (0.2828)	Prec@1 68.750 (88.601)
current lr 1.00000e-03
Valid: Test: [0/75]	Time 0.944 (0.944)	Loss 1.0286 (1.0286)	Prec@1 75.000 (75.000)
Valid: Test: [20/75]	Time 0.976 (0.915)	Loss 0.2954 (0.6101)	Prec@1 93.750 (80.060)
Valid: Test: [40/75]	Time 1.121 (0.919)	Loss 0.9953 (0.6281)	Prec@1 78.125 (79.649)
Valid: Test: [60/75]	Time 0.880 (0.940)	Loss 0.4240 (0.6475)	Prec@1 81.250 (78.586)
 * Prec@1 78.301
Checkpoint saved to ./resnet_model/model.th
Train: Epoch: [4][0/298]	Time 0.970 (0.970)	Data 0.212 (0.212)	Loss 0.3026 (0.3026)	Prec@1 81.250 (81.250)
Train: Epoch: [4][20/298]	Time 1.539 (1.238)	Data 0.781 (0.479)	Loss 0.5859 (0.2771)	Prec@1 78.125 (86.905)
Train: Epoch: [4][40/298]	Time 1.514 (1.281)	Data 0.756 (0.522)	Loss 0.2501 (0.2666)	Prec@1 84.375 (88.034)
Train: Epoch: [4][60/298]	Time 1.438 (1.304)	Data 0.680 (0.545)	Loss 0.2036 (0.2582)	Prec@1 87.500 (88.730)
Train: Epoch: [4][80/298]	Time 1.549 (1.323)	Data 0.791 (0.565)	Loss 0.1529 (0.2677)	Prec@1 96.875 (88.233)
Train: Epoch: [4][100/298]	Time 1.229 (1.343)	Data 0.471 (0.584)	Loss 0.2558 (0.2786)	Prec@1 90.625 (88.150)
Train: Epoch: [4][120/298]	Time 1.645 (1.357)	Data 0.886 (0.599)	Loss 0.5144 (0.2853)	Prec@1 78.125 (88.197)
Train: Epoch: [4][140/298]	Time 1.808 (1.383)	Data 1.050 (0.624)	Loss 0.4368 (0.2914)	Prec@1 75.000 (88.054)
Train: Epoch: [4][160/298]	Time 1.613 (1.393)	Data 0.855 (0.635)	Loss 0.2824 (0.2895)	Prec@1 87.500 (88.160)
Train: Epoch: [4][180/298]	Time 1.622 (1.409)	Data 0.864 (0.650)	Loss 0.1573 (0.2872)	Prec@1 96.875 (88.346)
Train: Epoch: [4][200/298]	Time 1.408 (1.420)	Data 0.647 (0.662)	Loss 0.2516 (0.2892)	Prec@1 87.500 (88.557)
Train: Epoch: [4][220/298]	Time 1.563 (1.434)	Data 0.805 (0.676)	Loss 0.5016 (0.2957)	Prec@1 78.125 (88.419)
Train: Epoch: [4][240/298]	Time 1.493 (1.449)	Data 0.735 (0.691)	Loss 0.1906 (0.2945)	Prec@1 93.750 (88.460)
Train: Epoch: [4][260/298]	Time 1.476 (1.465)	Data 0.718 (0.707)	Loss 0.4238 (0.2975)	Prec@1 81.250 (88.254)
Train: Epoch: [4][280/298]	Time 1.740 (1.477)	Data 0.982 (0.719)	Loss 0.4074 (0.2978)	Prec@1 84.375 (88.167)
current lr 1.00000e-03
Valid: Test: [0/75]	Time 0.890 (0.890)	Loss 0.5357 (0.5357)	Prec@1 84.375 (84.375)
Valid: Test: [20/75]	Time 0.427 (0.843)	Loss 0.3225 (0.4351)	Prec@1 90.625 (84.226)
Valid: Test: [40/75]	Time 0.791 (0.849)	Loss 0.6339 (0.4546)	Prec@1 71.875 (83.155)
Valid: Test: [60/75]	Time 0.823 (0.846)	Loss 0.2676 (0.4597)	Prec@1 87.500 (82.582)
 * Prec@1 82.296
Checkpoint saved to ./resnet_model/model.th
Best model saved to ./resnet_model/model_best.th
torch.Size([32, 1, 194, 259])
torch.Size([32, 1, 194, 259])
torch.Size([32, 1, 194, 259])
torch.Size([32, 1, 194, 259])
torch.Size([32, 1, 194, 259])
torch.Size([32, 1, 194, 259])
torch.Size([32, 1, 194, 259])
torch.Size([32, 1, 194, 259])
torch.Size([32, 1, 194, 259])
torch.Size([32, 1, 194, 259])
torch.Size([32, 1, 194, 259])
torch.Size([32, 1, 194, 259])
torch.Size([32, 1, 194, 259])
torch.Size([32, 1, 194, 259])
torch.Size([32, 1, 194, 259])
torch.Size([32, 1, 194, 259])
torch.Size([32, 1, 194, 259])
torch.Size([32, 1, 194, 259])
torch.Size([32, 1, 194, 259])
torch.Size([32, 1, 194, 259])
torch.Size([32, 1, 194, 259])
torch.Size([32, 1, 194, 259])
torch.Size([32, 1, 194, 259])
torch.Size([32, 1, 194, 259])
torch.Size([32, 1, 194, 259])
torch.Size([32, 1, 194, 259])
torch.Size([32, 1, 194, 259])
torch.Size([32, 1, 194, 259])
torch.Size([32, 1, 194, 259])
torch.Size([32, 1, 194, 259])
torch.Size([32, 1, 194, 259])
torch.Size([32, 1, 194, 259])
torch.Size([32, 1, 194, 259])
torch.Size([32, 1, 194, 259])
torch.Size([32, 1, 194, 259])
torch.Size([32, 1, 194, 259])
torch.Size([32, 1, 194, 259])
torch.Size([32, 1, 194, 259])
torch.Size([32, 1, 194, 259])
torch.Size([32, 1, 194, 259])
torch.Size([32, 1, 194, 259])
torch.Size([32, 1, 194, 259])
torch.Size([32, 1, 194, 259])
torch.Size([32, 1, 194, 259])
torch.Size([32, 1, 194, 259])
torch.Size([32, 1, 194, 259])
torch.Size([32, 1, 194, 259])
torch.Size([32, 1, 194, 259])
torch.Size([32, 1, 194, 259])
torch.Size([32, 1, 194, 259])
torch.Size([32, 1, 194, 259])
torch.Size([32, 1, 194, 259])
torch.Size([32, 1, 194, 259])
torch.Size([32, 1, 194, 259])
torch.Size([32, 1, 194, 259])
torch.Size([32, 1, 194, 259])
torch.Size([32, 1, 194, 259])
torch.Size([32, 1, 194, 259])
torch.Size([32, 1, 194, 259])
torch.Size([32, 1, 194, 259])
torch.Size([32, 1, 194, 259])
torch.Size([32, 1, 194, 259])
torch.Size([32, 1, 194, 259])
torch.Size([32, 1, 194, 259])
torch.Size([32, 1, 194, 259])
torch.Size([32, 1, 194, 259])
torch.Size([32, 1, 194, 259])
torch.Size([32, 1, 194, 259])
torch.Size([32, 1, 194, 259])
torch.Size([32, 1, 194, 259])
torch.Size([32, 1, 194, 259])
torch.Size([32, 1, 194, 259])
torch.Size([32, 1, 194, 259])
torch.Size([32, 1, 194, 259])
torch.Size([32, 1, 194, 259])
torch.Size([32, 1, 194, 259])
torch.Size([15, 1, 194, 259])
Train: Epoch: [5][0/298]	Time 1.428 (1.428)	Data 0.669 (0.669)	Loss 0.1471 (0.1471)	Prec@1 90.625 (90.625)
Train: Epoch: [5][20/298]	Time 1.501 (1.468)	Data 0.743 (0.709)	Loss 0.2506 (0.2938)	Prec@1 87.500 (87.351)
Train: Epoch: [5][40/298]	Time 1.642 (1.465)	Data 0.883 (0.706)	Loss 0.2182 (0.2908)	Prec@1 90.625 (87.652)
Train: Epoch: [5][60/298]	Time 1.744 (1.495)	Data 0.986 (0.736)	Loss 0.3173 (0.2876)	Prec@1 90.625 (88.268)
Train: Epoch: [5][80/298]	Time 1.584 (1.510)	Data 0.826 (0.751)	Loss 0.1888 (0.2811)	Prec@1 90.625 (88.657)
Train: Epoch: [5][100/298]	Time 1.428 (1.507)	Data 0.669 (0.748)	Loss 0.1766 (0.2770)	Prec@1 90.625 (88.583)
Train: Epoch: [5][120/298]	Time 1.627 (1.521)	Data 0.869 (0.762)	Loss 0.2086 (0.2712)	Prec@1 96.875 (89.101)
Train: Epoch: [5][140/298]	Time 1.382 (1.523)	Data 0.624 (0.764)	Loss 0.1339 (0.2663)	Prec@1 93.750 (89.184)
Train: Epoch: [5][160/298]	Time 1.597 (1.530)	Data 0.836 (0.772)	Loss 0.1977 (0.2759)	Prec@1 93.750 (88.684)
Train: Epoch: [5][180/298]	Time 1.672 (1.539)	Data 0.914 (0.780)	Loss 0.1326 (0.2757)	Prec@1 96.875 (88.674)
Train: Epoch: [5][200/298]	Time 1.363 (1.544)	Data 0.603 (0.786)	Loss 0.2330 (0.2733)	Prec@1 81.250 (88.775)
Train: Epoch: [5][220/298]	Time 1.444 (1.548)	Data 0.686 (0.790)	Loss 0.5729 (0.2785)	Prec@1 81.250 (88.730)
Train: Epoch: [5][240/298]	Time 1.672 (1.555)	Data 0.913 (0.797)	Loss 0.4138 (0.2789)	Prec@1 90.625 (88.797)
Train: Epoch: [5][260/298]	Time 1.494 (1.560)	Data 0.736 (0.802)	Loss 0.2051 (0.2789)	Prec@1 93.750 (88.841)
Train: Epoch: [5][280/298]	Time 1.836 (1.568)	Data 1.078 (0.810)	Loss 0.3459 (0.2835)	Prec@1 87.500 (88.623)
current lr 1.00000e-03
Valid: Test: [0/75]	Time 1.060 (1.060)	Loss 0.6800 (0.6800)	Prec@1 78.125 (78.125)
Valid: Test: [20/75]	Time 1.169 (1.007)	Loss 0.5974 (0.5293)	Prec@1 75.000 (80.804)
Valid: Test: [40/75]	Time 1.062 (1.029)	Loss 0.8625 (0.5618)	Prec@1 68.750 (79.878)
Valid: Test: [60/75]	Time 0.836 (1.043)	Loss 0.3200 (0.5614)	Prec@1 84.375 (79.662)
 * Prec@1 79.352
Checkpoint saved to ./resnet_model/model.th
Train: Epoch: [6][0/298]	Time 1.388 (1.388)	Data 0.630 (0.630)	Loss 0.3180 (0.3180)	Prec@1 87.500 (87.500)
Train: Epoch: [6][20/298]	Time 1.326 (1.295)	Data 0.567 (0.536)	Loss 0.1596 (0.3047)	Prec@1 90.625 (87.798)
Train: Epoch: [6][40/298]	Time 1.323 (1.289)	Data 0.565 (0.531)	Loss 0.1182 (0.2852)	Prec@1 96.875 (88.186)
Train: Epoch: [6][60/298]	Time 1.438 (1.320)	Data 0.680 (0.561)	Loss 0.1202 (0.2658)	Prec@1 100.000 (89.395)
Train: Epoch: [6][80/298]	Time 2.011 (1.352)	Data 1.252 (0.594)	Loss 0.2571 (0.2572)	Prec@1 84.375 (89.622)
Train: Epoch: [6][100/298]	Time 1.562 (1.379)	Data 0.804 (0.621)	Loss 0.1648 (0.2510)	Prec@1 93.750 (89.944)
Train: Epoch: [6][120/298]	Time 1.303 (1.394)	Data 0.544 (0.636)	Loss 0.3287 (0.2435)	Prec@1 90.625 (90.393)
Train: Epoch: [6][140/298]	Time 1.450 (1.408)	Data 0.692 (0.650)	Loss 0.2710 (0.2492)	Prec@1 87.500 (90.381)
Train: Epoch: [6][160/298]	Time 1.458 (1.422)	Data 0.700 (0.664)	Loss 0.1515 (0.2456)	Prec@1 96.875 (90.411)
Train: Epoch: [6][180/298]	Time 1.570 (1.428)	Data 0.812 (0.670)	Loss 0.2658 (0.2504)	Prec@1 87.500 (90.297)
Train: Epoch: [6][200/298]	Time 1.391 (1.437)	Data 0.633 (0.678)	Loss 0.2065 (0.2516)	Prec@1 90.625 (90.314)
